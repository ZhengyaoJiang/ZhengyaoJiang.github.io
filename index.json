[{"authors":null,"categories":null,"content":"I’m Zhengyao Jiang, a machine learning PhD student at UCL, supervised by Tim Rocktäschel and Edward Grefenstette. I’m generally interested in pushing Reinforcement Learning (RL) to work in real-world scenarios with limited online interaction. Some relavent topics are data-efficient RL, offline RL and transfer learning. On the methodology level, I’m now fascinated by model-based RL on a diverse dataset. I also have a background in neural symbolic methods and RL for financial trading before my PhD.\nHow to pronounce your name? Zheng = j-uhng, where j as in job; yao = y-aoww, where y as in you; Jiang = gee-ahng. If Zhengyao is still too difficult to pronounce, you can call me Yao.\n","date":1675036800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1675036800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m Zhengyao Jiang, a machine learning PhD student at UCL, supervised by Tim Rocktäschel and Edward Grefenstette. I’m generally interested in pushing Reinforcement Learning (RL) to work in real-world scenarios with limited online interaction.","tags":null,"title":"Zhengyao Jiang","type":"authors"},{"authors":["Yicheng Luo","Zhengyao Jiang","Samuel Cohen","Edward Grefenstette","Deisenroth Marc"],"categories":null,"content":"","date":1675036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675036800,"objectID":"f56c089b11f75ddbc283dc536938303a","permalink":"https://ZhengyaoJiang.github.io/publication/otr/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/otr/","section":"publication","summary":"We present an offline imitation learning based on optimal transport that demonstrates strong performance and sample efficiency","tags":[],"title":"Efficient Planning in a Compact Latent Action Space","type":"publication"},{"authors":["Zhengyao Jiang","Tianjun Zhang","Micheal Janner","Yueying Li","Tim Rocktäschel","Edward Grefenstette","Yuandong Tian"],"categories":null,"content":"","date":1675036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675036800,"objectID":"4d90243bd96aa7c2ed81673a58d0ac59","permalink":"https://ZhengyaoJiang.github.io/publication/tap/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/tap/","section":"publication","summary":"We propose a novel planning-based sequence modelling method that can scale to high dimensionality state-action space.","tags":[],"title":"Efficient Planning in a Compact Latent Action Space","type":"publication"},{"authors":["Zhengyao Jiang","Tianjun Zhang","Robert Kirk","Tim Rocktäschel","Edward Grefenstette"],"categories":null,"content":"","date":1653955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653955200,"objectID":"64f98c19d9e7794b931c71df980a52d1","permalink":"https://ZhengyaoJiang.github.io/publication/gb/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/gb/","section":"publication","summary":"We propose to treat the transition data of an MDP as a graph, and define a novel backup operator exploiting this graph structure. Comparing to multi-step backup, our graph backup method allows counterfactual credit assignment, and can reduce the variance that comes from stochastic environment dynamics.","tags":[],"title":"Graph Backup: Data Efficient Backup Exploiting Markovian Transitions","type":"publication"},{"authors":["Zhengyao Jiang","Tianjun Zhang","Robert Kirk","Tim Rocktäschel","Edward Grefenstette"],"categories":null,"content":"","date":1634083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634083200,"objectID":"632274e2bf98bac6b52eebdf9b9ec446","permalink":"https://ZhengyaoJiang.github.io/publication/gbworkshop/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/gbworkshop/","section":"publication","summary":"We propose to treat the transition data of an MDP as a graph, and define a novel backup operator exploiting this graph structure. Comparing to multi-step backup, our graph backup method allows counterfactual credit assignment, and can reduce the variance that comes from stochastic environment dynamics.","tags":[],"title":"Graph Backup: Data Efficient Backup Exploiting Markovian Data","type":"publication"},{"authors":["Zhengyao Jiang","Pasquale Minervini","Minqi Jiang","Tim Rocktaschel"],"categories":null,"content":"","date":1612742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612742400,"objectID":"a7e287d781c53e1af20b2204defdbbbf","permalink":"https://ZhengyaoJiang.github.io/publication/gtg/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/gtg/","section":"publication","summary":"We proposed a principled and flexible framework to encode relational inductive bias using a relational graph. The relational inductive biases are crucial for the generalization of neural network models and are usually hard-coded in the neural architectures.","tags":[],"title":"Grid-to-Graph: Flexible Spatial Relational Inductive Biases for Reinforcement Learning","type":"publication"},{"authors":["Zhengyao Jiang","Shan Luo"],"categories":null,"content":"","date":1556064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556064000,"objectID":"dfa4294f88e7f647c3d4a516255c4b1d","permalink":"https://ZhengyaoJiang.github.io/publication/nlrl/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/nlrl/","section":"publication","summary":"To address interpretability and generalization of DRL, we propose a novel algorithm named Neural Logic Reinforcement Learning (NLRL) to represent the policies in reinforcement learning by first-order logic.","tags":[],"title":"Neural Logic Reinforcement Learning","type":"publication"},{"authors":["Zhengyao Jiang","Dixing Xu","Jinjun Liang"],"categories":null,"content":"","date":1498780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498780800,"objectID":"fe7b3c2f6824d70573ce6b011a742b26","permalink":"https://ZhengyaoJiang.github.io/publication/deepportfolio/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/deepportfolio/","section":"publication","summary":"Financial portfolio management is the process of constant redistribution of a fund into different financial products. This paper presents a financial-model-free Reinforcement Learning framework to provide a deep machine learning solution to the portfolio management problem. The framework consists of the Ensemble of Identical Independent Evaluators (EIIE) topology, a Portfolio-Vector Memory (PVM), an Online Stochastic Batch Learning (OSBL) scheme, and a fully exploiting and explicit reward function. This framework is realized in three instants in this work with a Convolutional Neural Network (CNN), a basic Recurrent Neural Network (RNN), and a Long Short-Term Memory (LSTM). They are, along with a number of recently reviewed or published portfolio-selection strategies, examined in three back-test experiments with a trading period of 30 minutes in a cryptocurrency market. Cryptocurrencies are electronic and decentralized alternatives to government-issued money, with Bitcoin as the best-known example of a cryptocurrency. All three instances of the framework monopolize the top three positions in all experiments, outdistancing other compared trading algorithms. Although with a high commission rate of 0.25% in the backtests, the framework is able to achieve at least 4-fold returns in 50 days. ","tags":[],"title":"A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://ZhengyaoJiang.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]